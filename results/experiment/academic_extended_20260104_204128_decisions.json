[
  {
    "decision_id": "81124423",
    "timestamp": "2026-01-04T19:41:27.332052+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": null,
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 0,
    "query_text": "What is the speed of light?"
  },
  {
    "decision_id": "a91bce14",
    "timestamp": "2026-01-04T19:41:27.332748+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 1,
    "query_text": "Who discovered DNA structure?"
  },
  {
    "decision_id": "0f081e42",
    "timestamp": "2026-01-04T19:41:27.333266+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 2,
    "query_text": "What is the capital of France?"
  },
  {
    "decision_id": "65f021a5",
    "timestamp": "2026-01-04T19:41:27.333773+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 3,
    "query_text": "Which programming language was created by Guido van Rossum?"
  },
  {
    "decision_id": "c5ecef45",
    "timestamp": "2026-01-04T19:41:27.334251+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 4,
    "query_text": "What is the powerhouse of the cell?"
  },
  {
    "decision_id": "8bdc985f",
    "timestamp": "2026-01-04T19:41:27.334762+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 5,
    "query_text": "Who developed the theory of evolution?"
  },
  {
    "decision_id": "337e6ec0",
    "timestamp": "2026-01-04T19:41:27.335219+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 6,
    "query_text": "What equation is considered the most beautiful in mathematics?"
  },
  {
    "decision_id": "2a255759",
    "timestamp": "2026-01-04T19:41:27.335756+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 7,
    "query_text": "What did Marie Curie discover?"
  },
  {
    "decision_id": "76a8688a",
    "timestamp": "2026-01-04T19:41:27.336211+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 8,
    "query_text": "What technology allows for precise DNA editing?"
  },
  {
    "decision_id": "e6096402",
    "timestamp": "2026-01-04T19:41:27.336680+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 9,
    "query_text": "Which test evaluates machine intelligence against human intelligence?"
  },
  {
    "decision_id": "2ec55183",
    "timestamp": "2026-01-04T19:41:27.337124+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 10,
    "query_text": "What mathematical concept did Newton and Leibniz develop?"
  },
  {
    "decision_id": "47f60abc",
    "timestamp": "2026-01-04T19:41:27.337807+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 11,
    "query_text": "What mission landed humans on the Moon?"
  },
  {
    "decision_id": "adb27881",
    "timestamp": "2026-01-04T19:41:27.338260+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 12,
    "query_text": "What scientific theory revolutionized our understanding of gravity?"
  },
  {
    "decision_id": "7162b1c2",
    "timestamp": "2026-01-04T19:41:27.338710+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 13,
    "query_text": "What historical event marked the transition from medieval to modern times?"
  },
  {
    "decision_id": "97dec1c9",
    "timestamp": "2026-01-04T19:41:27.339187+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 14,
    "query_text": "What computing system is inspired by the human brain?"
  },
  {
    "decision_id": "5c132fdf",
    "timestamp": "2026-01-04T19:41:27.339645+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 15,
    "query_text": "Who won a Nobel Prize for discovering radioactive elements?"
  },
  {
    "decision_id": "68820ba7",
    "timestamp": "2026-01-04T19:41:27.340118+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 16,
    "query_text": "What scale measures how acidic or basic something is?"
  },
  {
    "decision_id": "7ec7d4c7",
    "timestamp": "2026-01-04T19:41:27.340632+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 17,
    "query_text": "What is the largest ocean on Earth?"
  },
  {
    "decision_id": "cefb3d0a",
    "timestamp": "2026-01-04T19:41:27.341205+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 18,
    "query_text": "Who wrote about a dystopian surveillance state?"
  },
  {
    "decision_id": "5198405c",
    "timestamp": "2026-01-04T19:41:27.341803+00:00",
    "selected_level": "deterministic_heuristic",
    "strategy_id": "relevance_scoring",
    "params": {
      "use_recency": true,
      "recency_weight": 0.3,
      "importance_threshold": 0.3
    },
    "explanation": "Selected deterministic_heuristic (Rule-based scoring (fastest, lowest cost)) | Reason: Task type 'memory_retrieve' works well with L1 | Strategy: relevance_scoring",
    "telemetry_tags": {
      "math.level": "deterministic_heuristic",
      "math.strategy": "relevance_scoring",
      "math.task_type": "memory_retrieve",
      "math.profile": "research",
      "session.length": "0",
      "memory.count": "45",
      "tenant.id": "unknown"
    },
    "features": {
      "task_type": "memory_retrieve",
      "memory_count": 45,
      "graph_density": 0.0,
      "session_length": 0,
      "memory_entropy": 0.0,
      "recent_mrr": 0.0,
      "recent_gcs": 0.0,
      "recent_scs": 0.0,
      "cost_budget": null,
      "latency_budget_ms": null,
      "previous_level": "deterministic_heuristic",
      "previous_level_success": null,
      "custom": {}
    },
    "confidence": 0.7,
    "query_index": 19,
    "query_text": "What economic theory was proposed by Adam Smith?"
  }
]